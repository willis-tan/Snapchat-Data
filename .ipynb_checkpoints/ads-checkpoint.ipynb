{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapchat Political Ads\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict the reach (number of views) of an ad.\n",
    "    * Predict how much was spent on an ad.\n",
    "    * Predict the target group of an ad. (For example, predict the target gender.)\n",
    "    * Predict the (type of) organization/advertiser behind an ad.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "The prediction problem we are attempting is predicting the reach (number of views) of an ad. This is a regression problem. For the baseline model, we are using the variables Duration and Spend to predict Impressions. These 2 variables seem to have the largest effect on Impressions. If the ad played for a longer time, by convention, it would have a higher number of Impressions. Also, if the spend on the ad was higher, then the ad would be expected to reach more viewers. We used R^2 to evalutate the accuracy of our predictions and trained 100 models to evaluate the variance fo the scores. For our improved model, we used the variables Duration, Spend, NumberInterestGroups, and CountryCode to predict Impressions. We used NumberInterestGroups because if the ad targeted specific interest groups, then the ad would be expected to reach less viewers than ads who target all viewers. We also used CountryCode because ads in countries with a larger population would be expected to gain more views. To evaluate the accuracy, we used R^2 and trained 100 models to evaluate the variance fo the scores.\n",
    "\n",
    "### Baseline Model\n",
    "For the baseline model, we are using 2 columns (spend and duration) as our features. These features are all quantitative. For this model we used LinearRegression to model. As a result, we got a total score of 0.7, but when we  used the cross_val_score function to generate 100 models to test the variance of the model there was a very high variance found using the current model, therefore the model we currently have is not good.\n",
    "\n",
    "### Final Model\n",
    "For our improved model, we used CountryCode and NumberInterestGroups. These 2 columns were originally ordinal, but we transformed them into quantitative variables. For the CountryCode, we changed the country code to its corresponding population. Countries with a greater population are expected to have more views. For the NumberInterestGroups, we derived it from the Interests column, by spliting each value by a comma to determine how many interests each ad targeted. Ads with more interests being targeted are expected to have more views. We also transformed all the quantitative features using SimpleIMputer to fill in null values with 0.Then we used a PolynomialTransformer on Spend, since Spend impacts Impressions exponentially. To select the best model, we created four different models and calculated the scores of the 4 models. We used the RandomForestRegressor as our model, because even though DecisionTreeRegressor yielded a higher score, the variance using that model was significantly higher than using the RandomForestRegressor. \n",
    "\n",
    "### Fairness Evaluation\n",
    "For the fairness evaluation, we decided to test the model against ads whose expenditures were in the top 10% and bottom 10%. Essentially, we want to see if the model has any bias towards ads that spend more or vice-versa. \n",
    "\n",
    "The test statistic that we will use for our permutation test is the absolute difference between the RMSE of both subsets.The significance level of our permutation test is 0.01. \n",
    "\n",
    "__Null Hypothesis__: The absolute difference between the RMSE of the groups is zero.  \n",
    "__Alternate Hypothesis__: The absolute difference between the RMSE of the groups is greater than zero.  \n",
    "\n",
    "Our observed statistic is 329950.484412926.  \n",
    "\n",
    "We used 1000 as the number of permutations needed for the test. After 1000 permutations, we computed the number ofstatistics that were greater than our observed statistic and calculated the mean. This resulted in a p-value of 1.0. Since 1.0 >0.01, we cannot reject the null hypothesis. Thus, there is suggestion that our Random Forest model predicts fairly for both subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "We converted StartDate and EndDate into a feature that showed the duration of the ad in hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ads_18 = pd.read_csv(\"PoliticalAds2018.csv\")\n",
    "ads_19 = pd.read_csv(\"PoliticalAds2019.csv\")\n",
    "ads_18[\"StartDate\"] = pd.to_datetime(ads_18[\"StartDate\"])\n",
    "ads_19[\"StartDate\"] = pd.to_datetime(ads_19[\"StartDate\"])\n",
    "ads_18[\"EndDate\"] = pd.to_datetime(ads_18[\"EndDate\"])\n",
    "ads_19[\"EndDate\"] = pd.to_datetime(ads_19[\"EndDate\"])\n",
    "\n",
    "idx_18 = ads_18.EndDate < ads_18.StartDate\n",
    "ads_18.loc[idx_18] = ads_18.loc[idx_18].rename(columns={'EndDate':'StartDate','StartDate':'EndDate'})\n",
    "idx_19 = ads_19.EndDate < ads_19.StartDate\n",
    "ads_19.loc[idx_19] = ads_19.loc[idx_19].rename(columns={'EndDate':'StartDate','StartDate':'EndDate'})\n",
    "\n",
    "avg_runtime_18 = (ads_18.EndDate - ads_18.StartDate).mean()\n",
    "avg_runtime_19 = (ads_19.EndDate - ads_19.StartDate).mean()\n",
    "ads_18.EndDate = ads_18.EndDate.fillna(avg_runtime_18 + ads_18.StartDate)\n",
    "ads_19.EndDate = ads_19.EndDate.fillna(avg_runtime_19 + ads_19.StartDate)\n",
    "df = pd.concat([ads_18,ads_19], ignore_index=True)\n",
    "df['Duration'] = df.EndDate - df.StartDate\n",
    "\n",
    "not_needed = ['OrganizationName', 'BillingAddress',\n",
    "               'CandidateBallotInformation', 'PayingAdvertiserName', \n",
    "               'CountryCode', 'Regions (Included)', 'Regions (Excluded)',\n",
    "               'Electoral Districts (Included)', 'Electoral Districts (Excluded)',\n",
    "               'Radius Targeting (Included)', 'Radius Targeting (Excluded)',\n",
    "               'Metros (Included)', 'Metros (Excluded)', 'Postal Codes (Included)',\n",
    "               'Postal Codes (Excluded)', 'Location Categories (Included)',\n",
    "               'Location Categories (Excluded)', 'Targeting Connection Type', 'Targeting Carrier (ISP)']\n",
    "\n",
    "df2 = df.drop(not_needed, axis = 1)\n",
    "hours = df2.Duration.astype('timedelta64[h]')\n",
    "df2['Duration'] = hours\n",
    "df2 = df2.drop('StartDate', axis = 1)\n",
    "df2 = df2.drop('EndDate', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separated the columns that were objects with columns that weren't objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spend         int64\n",
       "Duration    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = df2[[\"Spend\",\"Duration\"]].dtypes\n",
    "catcols = types.loc[types == np.object].index\n",
    "numcols = types.loc[types != np.object].index\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our baseline model. We used SimpleImputer, OneHotEncoder and PCA to handle all the categorical variables. We filled in all the null values with NULL. For the quantititaive variables we used SimpleImputer to fill all the null values with zero. Lastly, we used LinearRegression as our model. We ended up with a score of 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094744225346112"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    ('pca', PCA(svd_solver='full', n_components=0.99))\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('catcols', cats, catcols),\n",
    "    ('numcols', SimpleImputer(strategy='constant', fill_value=0), numcols)\n",
    "])\n",
    "\n",
    "b_pl = Pipeline([('feats', ct), ('reg', LinearRegression())])\n",
    "b_pl.fit(df2[['Spend', 'Duration']], df2.Impressions)\n",
    "preds = b_pl.predict(df2[['Spend', 'Duration']])\n",
    "np.sqrt(np.mean((preds - df2.Impressions)**2))\n",
    "b_pl.score(df2[['Spend', 'Duration']], df2.Impressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found scores in 100 models with different sample of data to determine the variance of our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = []\n",
    "for _ in range(100):\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(df2[['Spend',\"Duration\"]], df2.Impressions, test_size=4)\n",
    "    b_pl.fit(X_tr, y_tr)\n",
    "    out.append(b_pl.score(X_ts, y_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 388
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(out).plot(kind='hist', title='scores in 100 model builds');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance is very high, therefore this baseline model is not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the feature transformations for the improved model. We converted Interest columns into a quantitative column thatrepresents the number of interests targeted by the ad. We converted Spend to USD dollars, so that spend is standardized. Wealso converted CountryCode to its corresponding population value. Lastly, we dropped data that were outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['NumberInterestGroups'] = df2[\"Interests\"].str.split(\",\").fillna(\"\").apply(lambda x: len(x))\n",
    "def convert_to_usd(row):\n",
    "    x=row['Currency Code']\n",
    "    y=row['Spend']\n",
    "    rates = {'CAD': 0.71774,\n",
    "             'USD': 1,\n",
    "              'AUD': 0.65254,\n",
    "              'GBP': 1.23979,\n",
    "              'EUR': 1.08331}\n",
    "    return int(round(rates[x] * y))\n",
    "df2.Spend = df.apply(convert_to_usd, axis=1)\n",
    "df2 = df2.drop(['Currency Code'], axis = 1)\n",
    "\n",
    "pops = {\"netherlands\":17.28,\"united states\": 328.2, \"denmark\": 5.806, \"norway\": 5.368, \"switzerland\": 8.57, \"canada\": 37.59, \"ireland\": 4.904, \"france\": 66.99, \"united kingdom\": 66.65, \"nigeria\": 195.9, \"sweden\": 10.23, \"australia\": 24.99, \"finland\": 5.518, \"india\": 1353, \"united arab emirates\": 9.631, \"germany\": 83.02, \"argentina\": 44.49, \"turkey\": 82, \"south africa\": 57.78, \"kuwait\": 4.137, \"lithuania\": 2.794, \"new zealand\": 4.886, \"poland\": 37.97, \"brazil\": 209.5, \"puerto rico\": 3.194, \"chile\": 18.73, \"iraq\": 38.43, \"belgium\": 11.46, \"austria\": 24.99}\n",
    "df2[\"CountryCode\"]=df[\"CountryCode\"].map(pops)\n",
    "df2=df2[[\"Spend\",\"Impressions\",\"CountryCode\",\"Duration\",\"NumberInterestGroups\"]]\n",
    "df2=df2[df2[\"Duration\"]>0]\n",
    "df2=df2[df2[\"Impressions\"]<df2[\"Impressions\"].quantile(0.98)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made 4 models using RandomForestRegressor, KNeighborsRegressor, DecisionTreeRegressor, and LogisticRegression to find the best model for our data. Although the DecisionTreeRegressor scored slightly higher than the RandomForestRegressor, we decided to still use the RandomForestRegressor because this model yielded less variance than the DecisionTreeRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\willis tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.011483</th>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.825188</th>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.964915</th>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999854</th>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model\n",
       "Score                        \n",
       "0.011483  Logistic Regression\n",
       "0.825188                  KNN\n",
       "0.964915        Random Forest\n",
       "0.999854        Decision Tree"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df2[['Spend', 'NumberInterestGroups', \"CountryCode\", \"Duration\"]],\n",
    "                                                    df2.Impressions, test_size=0.25)\n",
    "\n",
    "random_forest = RandomForestRegressor(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "score_random_forest = random_forest.score(X_train, Y_train)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = 3) \n",
    "knn.fit(X_train, Y_train)  \n",
    "Y_pred = knn.predict(X_test)  \n",
    "score_knn = knn.score(X_train, Y_train)\n",
    "\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree.fit(X_train, Y_train)  \n",
    "Y_pred = decision_tree.predict(X_test)  \n",
    "score_decision_tree = decision_tree.score(X_train, Y_train)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "score_log = logreg.score(X_train, Y_train)\n",
    "\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Logistic Regression', \n",
    "              'Random Forest', \n",
    "              'Decision Tree'],\n",
    "    'Score': [score_knn, score_log, score_random_forest, score_decision_tree]})\n",
    "result_df = results.sort_values(by='Score')\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the relative importance of each feature. Spend ended up being significantly more important than all the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2.drop(['Impressions'], axis=1), df2.Impressions, test_size=0.10)\n",
    "reg = RandomForestRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "dict(zip(df2.drop(['Impressions'], axis=1).columns, reg.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempted a gridsearch to find the best parameter for RandomForestRegressor. We could have done more parameters, but unfortunately the code would have run for too long, thus unable being to provide a viable result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2.drop(['Impressions'], axis=1), df2.Impressions, test_size=0.1)\n",
    "parameters = { \n",
    "    \"n_estimators\": [100, 200, 500, 1000]\n",
    "}\n",
    "\n",
    "reg = GridSearchCV(estimator=RandomForestRegressor(), param_grid=parameters)\n",
    "reg.fit(X_train, y_train)\n",
    "reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our improved model using the features NumberInterstGroups, CountryCode, Duration, and Spend. We used PolynomialFeatures to transform spend, since spend is significantly more important than the other features. For the other features, we used SimpleImputer to fill in all the possible null values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_feat = ['NumberInterestGroups', \"CountryCode\", \"Duration\"]\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "])\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers=[('spend', PolynomialFeatures(degree=2), [\"Spend\"]),\n",
    "                                          (\"num\", num_transformer, num_feat)\n",
    "                                         ])\n",
    "\n",
    "pl = Pipeline([('preprocessor', preproc), ('reg', RandomForestRegressor(n_estimators=100))])\n",
    "\n",
    "pl.fit(df2.drop(\"Impressions\", axis=1), df2[\"Impressions\"])\n",
    "\n",
    "pl.score(df2.drop('Impressions', axis=1), df2.Impressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found scores in 100 models with different sample of data to determine the variance of our improved mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = []\n",
    "for _ in range(100):\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(df2[['Spend', 'NumberInterestGroups', \"CountryCode\", \"Duration\"]], df2.Impressions, test_size=0.25)\n",
    "    pl.fit(X_tr, y_tr)\n",
    "    out.append(pl.score(X_ts, y_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(out).plot(kind='hist', title='scores in 100 model builds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting subset of our data is the upperbound (90% quantile of the data) and the lowerbound (10% quantile of the data) of Spend. We performed a permutation test to see if our final model fairly predicts the data when the we use data with Spend thatis within the lower bound and data with Spend that is within the upper bound.  \n",
    "\n",
    "**Null Hypothesis**: Our improved model fairly predicts across lower bound Spend and upper bound Spend  \n",
    "**Alternative Hypothesis**: Our improved model does not fairly predict across lower bound Spend and upper bound Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_repetitions = 1000\n",
    "perm_test = df2.copy()\n",
    "lower_bound = perm_test.Impressions.quantile(0.10)\n",
    "upper_bound = perm_test.Impressions.quantile(0.90)\n",
    "\n",
    "top_10 = perm_test.loc[perm_test.Impressions >= upper_bound]\n",
    "bottom_10 = perm_test.loc[perm_test.Impressions <= lower_bound]\n",
    "    \n",
    "upper_preds = pl.predict(top_10.drop(['Impressions'], axis=1))\n",
    "lower_preds = pl.predict(bottom_10.drop(['Impressions'], axis=1))\n",
    "    \n",
    "upper_rmse = np.sqrt(np.mean((upper_preds - top_10.Impressions)**2))\n",
    "lower_rmse = np.sqrt(np.mean((lower_preds - bottom_10.Impressions)**2))\n",
    "    \n",
    "obs_stat = abs(upper_rmse - lower_rmse)\n",
    "\n",
    "diffs = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    shuffled_col = (\n",
    "        perm_test['Impressions']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    shuffled = (\n",
    "        perm_test\n",
    "        .assign(**{\n",
    "            'Impressions': shuffled_col,\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    top_10 = shuffled.loc[shuffled.Impressions >= upper_bound]\n",
    "    bottom_10 = shuffled.loc[shuffled.Impressions <= lower_bound]\n",
    "    \n",
    "    upper_preds = pl.predict(top_10.drop(['Impressions'], axis=1))\n",
    "    lower_preds = pl.predict(bottom_10.drop(['Impressions'], axis=1))\n",
    "    \n",
    "    upper_rmse = np.sqrt(np.mean((upper_preds - top_10.Impressions)**2))\n",
    "    lower_rmse = np.sqrt(np.mean((lower_preds - bottom_10.Impressions)**2))\n",
    "    \n",
    "    test_stat = abs(upper_rmse - lower_rmse)\n",
    "    diffs.append(test_stat)\n",
    "\n",
    "np.mean(np.array(diffs) > obs_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = np.mean(np.array(diffs) > obs_stat)\n",
    "pd.Series(np.array(diffs)).plot(kind='hist',density=True,alpha=0.8,title='p-value: %f'%pval)\n",
    "plt.scatter(obs_stat,0,color='red',s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Since the observed value does not even lie within the histogram, we reject the null hypothesis. This suggests our improved model does not predict accurately across the lower and upper bounds of Spend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
